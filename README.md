# Capstone_1_MSBA_u1459694
A repository to store all my files created for my Capstone 1 project on Home Credit
## Business Problem and Project Objective
Home Credit faces the challenge of accurately predicting the loan repayment capabilities of a specific group with a non-existent or limited credit history, which poses the risk of rejecting clients capable of repayment. The objective of this project is to do Exploratory Data Analysis and Model creation using the dataset provided by Home Credit to accurately predict whether a customer will have payment difficulties (i.e. TARGET = 1) or not. 
The EDA phase is designed to thoroughly examine and comprehend the dataset's characteristics before applying appropriate modeling or analysis techniques. The modeling task is focused on creating a predictive model that achieves the best possible Kaggle score, thereby predicting whether a Home Credit client will default on their loan. This model assists the company in making decisions regarding whether to extend a loan contract to an individual, by striking an optimal balance between revenue loss and opportunity cost.
## Solution
Among the four models tested, including Recursive Partitioning (Part), LightGBM (Light Gradient Boosting Machine), Gradient Boosting, and XGBoost (eXtreme Gradient Boosting), the XGBoost model was chosen due to its highest AUC value and Kaggle score. It's worth noting that XGBoost provides probabilistic outputs rather than deterministic ones.
To evaluate the XGBoost model's performance in the context of Home Credit's business model, two variables were utilized to quantify costs.
The first variable is the loss of revenue, representing the cost incurred by the company when the model predicts that a customer will not default, but they ultimately do default. This is calculated as: Loss of Revenue = Loan Amount * APR * P(Default).
The second cost factor is the Opportunity Cost, which encompasses the potential profit loss, goodwill cost, and processing fee incurred when the model predicts a default that doesn't occur. Opportunity Cost = Potential Profit + Goodwill Cost + Processing Fee.
The balance point occurs when the Loss of Revenue equals the Opportunity Cost. Beyond this point, the Loss of Revenue surpasses the Opportunity Cost, indicating that extending the loan to that customer would not be prudent.
## My Contribution
I proposed quantifying the implementation costs of our Modeling notebook results within HomeCredit's business framework. Additionally, I conducted independent Exploratory Data Analysis (EDA) and developed my own XGBoost model, adjusting hyperparameters to optimize results.
## Business Value of the solution
This solution addresses Home Credit's challenge of accurately predicting loan repayment capabilities and minimizing the risk of rejecting creditworthy clients. The selected XGBoost model provides a robust predictive tool, allowing Home Credit to quantify potential costs and optimize lending decisions. By considering both revenue loss and opportunity cost, the model helps Home Credit strike an optimal balance between profitability and risk.
## Difficulties Encountered
One of the main challenges encountered in this project was the high class imbalance in the target variable, with only 8% of the dataset representing customers who defaulted. To address this, oversampling was necessary which was achieved through the SMOTE Package in R, reducing the imbalance to approximately 70/30. However, this led to a significantly larger dataset of 7 million observations, making it challenging to train an XGBoost model efficiently using a single computer.
## Learnings
This project provided me with the opportunity to conduct Exploratory Data Analysis (EDA) with a large number of predictors, i.e. 122. Through this process, I acquired new visualization techniques, such as multivariable scatter plots and heatmaps, to effectively explore the data. Additionally, I gained insights into various ensemble models, including Gradient Boosting and XGBoost, and learned how to fine-tune hyperparameters and utilize grid search to optimize model performance.
